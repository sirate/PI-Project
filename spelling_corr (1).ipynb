{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spelling_corr",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Installation of needed packages**\n"
      ],
      "metadata": {
        "id": "pcdCxL49BkAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc71C105BpGo",
        "outputId": "1e11f27f-eb36-41b5-a470-86d53cf033c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autocorrect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGiZaJ8ZBtR0",
        "outputId": "997296ee-368b-4086-dd73-f4c5d492ac05"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autocorrect\n",
            "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 30 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 61 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 71 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 92 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 440 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 450 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 460 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 471 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 481 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 491 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 501 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 512 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 522 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 532 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 542 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 552 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 563 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 573 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 583 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 593 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 604 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 614 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 622 kB 5.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622382 sha256=47352b4d1508fba070b42fe4cf2f02fea2685c037f99254fa065c551f1e1dd87\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/d4/37/8244101ad50b0f7d9bffd93ce58ed7991ee1753b290923934b\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspellchecker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-AGLT20CDoo",
        "outputId": "bdf0f86e-bd5f-4ee8-a9e2-7c2392eb97b5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.6.3-py3-none-any.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 5.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pattern"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fBZW9fZCGr0",
        "outputId": "d23fa6ba-4406-44a7-e32f-3001ac906018"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pattern\n",
            "  Downloading Pattern-3.6.0.tar.gz (22.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.2 MB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pattern) (0.16.0)\n",
            "Collecting backports.csv\n",
            "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
            "Collecting mysqlclient\n",
            "  Downloading mysqlclient-2.1.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from pattern) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pattern) (4.2.6)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting pdfminer.six\n",
            "  Downloading pdfminer.six-20220319-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 34.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pattern) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pattern) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pattern) (3.2.5)\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 21.5 MB/s \n",
            "\u001b[?25hCollecting cherrypy\n",
            "  Downloading CherryPy-18.6.1-py2.py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 53.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pattern) (2.23.0)\n",
            "Collecting zc.lockfile\n",
            "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting cheroot>=8.2.1\n",
            "  Downloading cheroot-8.6.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 54.4 MB/s \n",
            "\u001b[?25hCollecting portend>=2.1.1\n",
            "  Downloading portend-3.1.0-py3-none-any.whl (5.3 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from cherrypy->pattern) (8.12.0)\n",
            "Collecting jaraco.collections\n",
            "  Downloading jaraco.collections-3.5.1-py3-none-any.whl (10 kB)\n",
            "Collecting jaraco.functools\n",
            "  Downloading jaraco.functools-3.5.0-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from cheroot>=8.2.1->cherrypy->pattern) (1.15.0)\n",
            "Collecting tempora>=1.8\n",
            "  Downloading tempora-5.0.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern) (2018.9)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "Collecting jaraco.text\n",
            "  Downloading jaraco.text-3.7.0-py3-none-any.whl (8.6 kB)\n",
            "Collecting jaraco.classes\n",
            "  Downloading jaraco.classes-3.2.1-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (5.4.0)\n",
            "Collecting jaraco.context>=4.1\n",
            "  Downloading jaraco.context-4.1.1-py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->jaraco.text->jaraco.collections->cherrypy->pattern) (3.7.0)\n",
            "Collecting cryptography\n",
            "  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 35.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->pattern) (3.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six->pattern) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six->pattern) (2.21)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (2.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zc.lockfile->cherrypy->pattern) (57.4.0)\n",
            "Building wheels for collected packages: pattern, mysqlclient, python-docx, sgmllib3k\n",
            "  Building wheel for pattern (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pattern: filename=Pattern-3.6-py3-none-any.whl size=22332721 sha256=68af583925dbc642b5d9b98b6f8d457a5ac99460fab289a01e7292ccf0d821ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/1f/4e/9b67afd2430d55dee90bd57618dd7d899f1323e5852c465682\n",
            "  Building wheel for mysqlclient (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysqlclient: filename=mysqlclient-2.1.0-cp37-cp37m-linux_x86_64.whl size=99974 sha256=539fde8acbf1e8369421a9a12893d38befc457816d996f8581a13cc35ea8dc11\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/d4/df/08cd6e1fa4a8691b268ab254bd0fa589827ab5b65638c010b4\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184507 sha256=30ff1cc69df012838ab920bcf7868fa2bbf48f1317a8cd4867c78646f75694ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=52f1dc2122cd66cd21c68466eb8fa0b1e9138888c7632a008b28d18b4c0d8289\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
            "Successfully built pattern mysqlclient python-docx sgmllib3k\n",
            "Installing collected packages: jaraco.functools, jaraco.context, tempora, jaraco.text, jaraco.classes, zc.lockfile, sgmllib3k, portend, jaraco.collections, cryptography, cheroot, python-docx, pdfminer.six, mysqlclient, feedparser, cherrypy, backports.csv, pattern\n",
            "Successfully installed backports.csv-1.0.7 cheroot-8.6.0 cherrypy-18.6.1 cryptography-36.0.2 feedparser-6.0.8 jaraco.classes-3.2.1 jaraco.collections-3.5.1 jaraco.context-4.1.1 jaraco.functools-3.5.0 jaraco.text-3.7.0 mysqlclient-2.1.0 pattern-3.6 pdfminer.six-20220319 portend-3.1.0 python-docx-0.8.11 sgmllib3k-1.0.0 tempora-5.0.1 zc.lockfile-2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PySpellChecker**\n",
        "\n",
        "\n",
        "*   Find Unknown Spelling\n",
        "*   Autocorrect\n",
        "\n",
        "*   Suggested Candidates\n",
        "*   Supply our own list of words\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uGo-H-_hCTaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Packages\n",
        "from spellchecker import SpellChecker"
      ],
      "metadata": {
        "id": "Pe7H8kbfCwBa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(SpellChecker)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afcLLekzDDJ0",
        "outputId": "0cf1d8b9-9645-4702-b5ca-d2407f3c2fa0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_SpellChecker__edit_distance_alt',\n",
              " '__class__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '_case_sensitive',\n",
              " '_check_if_should_check',\n",
              " '_distance',\n",
              " '_tokenizer',\n",
              " '_word_frequency',\n",
              " 'candidates',\n",
              " 'correction',\n",
              " 'distance',\n",
              " 'edit_distance_1',\n",
              " 'edit_distance_2',\n",
              " 'export',\n",
              " 'known',\n",
              " 'languages',\n",
              " 'split_words',\n",
              " 'unknown',\n",
              " 'word_frequency',\n",
              " 'word_probability',\n",
              " 'word_usage_frequency']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load default word frequency list \n",
        "spell = SpellChecker()\n",
        "spell.languages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmzA2VFeDFgU",
        "outputId": "b54feee6-17f2-4939-85e6-ddfaaee06f28"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method SpellChecker.languages of <class 'spellchecker.spellchecker.SpellChecker'>>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docx = [\"thusnd\",\"sevn\",\"sx\",\"hund\",\"lak\"]"
      ],
      "metadata": {
        "id": "a1PfBjfxDkHc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spelling Correction**"
      ],
      "metadata": {
        "id": "OwpCCOsVEQaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word in docx:\n",
        "  print(f'{word}:{spell.correction(word)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NutStvCENpz",
        "outputId": "83dd5592-ff41-4473-c682-9d1ca99c868f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thusnd:thousand\n",
            "sevn:seen\n",
            "sx:so\n",
            "hund:hand\n",
            "lak:law\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Suggested candidates**"
      ],
      "metadata": {
        "id": "cD8aoW_0Gd1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word in docx:\n",
        "  print(f'{word}:{spell.candidates(word)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD-2dlPbEi63",
        "outputId": "0c5b8455-b1f4-4ea4-b565-b3106d068b27"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thusnd:{'tousand', 'thusly', 'tound', 'thus', 'thunk', \"this'd\", 'thousend', 'thuds', 'husand', 'thisand', 'thind', 'thun', 'thud', 'thousand', 'theend'}\n",
            "sevn:{'sewn', 'sean', 'seon', 'sen', 'sven', 'sein', 'seven', 'sev', 'seva', 'seen'}\n",
            "sx:{'ix', 'si', 'ax', 'su', 'sax', 'sex', 'six', 'sy', 'sux', 'so', 'se', 'sox', 'ox', 'sa', 'ex'}\n",
            "hund:{'hunt', 'hound', 'ound', 'hind', 'fund', 'huns', 'hun', 'hud', 'lund', 'und', 'hung', 'hundr', 'hunc', 'hand', 'mund', 'hundy', 'bund', 'hundo', 'hued', 'hunk'}\n",
            "lak:{'lok', 'lark', 'lakh', 'oak', 'luk', 'laka', 'law', 'leak', 'lik', 'blak', 'lao', 'lan', 'kak', 'jak', 'lar', 'lac', 'laik', 'lal', 'lah', 'zak', 'laa', 'lab', 'lat', 'hak', 'lack', 'lek', 'pak', 'sak', 'lau', 'flak', 'eak', 'lask', 'lag', 'lake', 'ak', 'lav', 'gak', 'yak', 'rak', 'lahk', 'lap', 'lay', 'mak', 'nak', 'la', 'las', 'cak', 'lank', 'bak', 'lad', 'tak', 'lax', 'alak', 'wak', 'lam', 'lai', 'dak', 'alk', 'fak'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The frquency of the given word out of all words in the frequency list**"
      ],
      "metadata": {
        "id": "pRdMtWfwHcdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word in docx:\n",
        "  print(f'{word}:{spell.correction(word)}:probability {spell.word_probability(word)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9atRapuWGxjZ",
        "outputId": "4234e88f-64d4-41af-d4f5-23697ec2c7a4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thusnd:thousand:probability 0.0\n",
            "sevn:seen:probability 0.0\n",
            "sx:so:probability 0.0\n",
            "hund:hand:probability 0.0\n",
            "lak:law:probability 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Function word_probability is now deprecated! Deprecated as of version 0.6.5; use word_usage_frequency instead\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preventing Certain Words From Being Flagged as Misspelt**"
      ],
      "metadata": {
        "id": "rbwoYjUzIxB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Autocorrect**"
      ],
      "metadata": {
        "id": "GqFM45w4Kuge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autocorrect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTHWgKPmKxMS",
        "outputId": "06c988db-68d0-4d83-fe4f-08e97c2feb3a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: autocorrect in /usr/local/lib/python3.7/dist-packages (2.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load package\n",
        "from autocorrect import spell"
      ],
      "metadata": {
        "id": "i_5wbURhKzNk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S007ToXgK3ge",
        "outputId": "08d529aa-1aa3-4d4c-97f9-64e754ea7c7f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['thusnd', 'sevn', 'sx', 'hund', 'lak']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in docx:\n",
        "  print(spell(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl8TwEJYK60i",
        "outputId": "4c4dec03-3725-4f00-ed4d-575eca8e2719"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "thus\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "seen\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "sx\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "hand\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "lak\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Textblob**"
      ],
      "metadata": {
        "id": "Kzw4xDEJLN1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load packages\n",
        "from textblob import TextBlob,Word"
      ],
      "metadata": {
        "id": "xVeltyzsK_ok"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex= TextBlob(\"One thusnd thre hunded\")"
      ],
      "metadata": {
        "id": "d1Ag44h7LVr_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m textblob.download_corpora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJKo3mL0MO1C",
        "outputId": "6a270585-e8f3-4541-db22-eb8f848945a8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in ex.words:\n",
        "  print(word,\":\",word.correct())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Moz_Y0wLfMA",
        "outputId": "dae4ec2c-4273-467f-a218-e1ea79690e60"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One : One\n",
            "thusnd : thousand\n",
            "thre : the\n",
            "hunded : hundred\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stand alone dictionary**"
      ],
      "metadata": {
        "id": "tTJoES4cM6YO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX8N5htzPDxt",
        "outputId": "f8f4bd2e-f474-42a3-c0e2-d2b45fb2fc75"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spell = SpellChecker(language=None)\n",
        "\n",
        "spell.word_frequency.load_text_file('/content/drive/MyDrive/my_text_file.txt')"
      ],
      "metadata": {
        "id": "tAGSaQT0Llgo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in docx:\n",
        "  print(f'{word}:{spell.correction(word)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MttzLe-PcAS",
        "outputId": "8c17ba78-5479-4160-94a3-a9962c1352f7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thusnd:thousand\n",
            "sevn:seven\n",
            "sx:six\n",
            "hund:hund\n",
            "lak:lakh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docx_1 = [\"oe\",\"thound\",\"thre\",\"hundrd\",\"las\"]"
      ],
      "metadata": {
        "id": "SCE3X0V-Pn_U"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in docx_1:\n",
        "  print(f'{word}:{spell.correction(word)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4Tfg5YFQO48",
        "outputId": "2bfef8f3-5ba0-410c-cd1a-0f4ffd357a9a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "oe:one\n",
            "thound:thousand\n",
            "thre:three\n",
            "hundrd:hundred\n",
            "las:lakh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docx_2 = [\"to\",\"ousand\",\"fv\",\"ndred\",\"las\"]"
      ],
      "metadata": {
        "id": "uG4xOBvuQUyJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in docx_2:\n",
        "  print(f'{word}:{spell.correction(word)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epA6NaW8RUC7",
        "outputId": "472420a2-b3eb-4aa8-c858-b7456311194e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to:two\n",
            "ousand:thousand\n",
            "fv:five\n",
            "ndred:hundred\n",
            "las:lakh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docx_3 = [\"for\",\"touand\",\"iv\",\"hndrd\",\"lhs\"]"
      ],
      "metadata": {
        "id": "Ls-KL4-ERXYY"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in docx_3:\n",
        "  print(f'{word}:{spell.correction(word)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tflpwaoGRpw0",
        "outputId": "12e37aec-f784-4249-d80a-15edd29c3fb9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for:four\n",
            "touand:thousand\n",
            "iv:five\n",
            "hndrd:hundred\n",
            "lhs:lakhs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docx_4 = [\"fur\",\"toand\",\"iv\",\"hndrd\",\"lhs\"]"
      ],
      "metadata": {
        "id": "DxPe39moRsCu"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list=[]\n",
        "for word in docx_4:\n",
        "  print(spell.correction(word))\n",
        "  #add predicted words to a list\n",
        "  list.append(spell.correction(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFgHU2izSjlx",
        "outputId": "87607472-fffd-4fd6-c243-663dcbc44c6d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "four\n",
            "toand\n",
            "five\n",
            "hundred\n",
            "lakhs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#list of predicted words \n",
        "for i in list:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBBe8AOtS9N0",
        "outputId": "52d4575e-14b5-490e-fea0-bc55ee64a7a1"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "four\n",
            "toand\n",
            "five\n",
            "hundred\n",
            "lakhs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#our dictionnary of words\n",
        "list_of_words = [\"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\",\"nine\",\"ten\",\"eleven\",\"twelve\",\"thirteen\",\"fourteen\",\"fifteen\",\"sixteen\",\"seventeen\",\"eighteen\",\"nineteen\",\"twenty\",\"thirty\",\"forty\",\"fifty\",\"sixty\",\"seventy\",\"eighty\",\"ninety\",\"hundred\",\"thousand\",\"million\",\"lakh\",\"lakhs\"] \n",
        "#check for words predicted uncorrectly\n",
        "list_of_uncorrect_words=[]\n",
        "for i in list:\n",
        "  if i not in list_of_words:\n",
        "    list_of_uncorrect_words.append(i)\n",
        "list_of_uncorrect_words\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5Q3Jyr-IAnp",
        "outputId": "09899a1f-df6c-4c7a-bbcb-9ac445a715e4"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['toand']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking similarities for uncorrect predicted words with probability**"
      ],
      "metadata": {
        "id": "A9C9GoVCHkHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#testing functionality of similarity \n",
        "import difflib\n",
        "string =\"thousand\"\n",
        "string1=\"toand\"\n",
        "temp = difflib.SequenceMatcher(None,string,string1)\n",
        "print(temp.get_matching_blocks())\n",
        "print('similarity Score: ',temp.ratio())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geLySlmWYLP5",
        "outputId": "a5f55131-8ef7-458a-d20d-6cfb1149b3f2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Match(a=0, b=0, size=1), Match(a=2, b=1, size=1), Match(a=5, b=2, size=3), Match(a=8, b=5, size=0)]\n",
            "similarity Score:  0.7692307692307693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string =\"thousand\"\n",
        "string1=\"thous\"\n",
        "temp = difflib.SequenceMatcher(None,string,string1)\n",
        "print(temp.get_matching_blocks())\n",
        "print('similarity Score: ',temp.ratio())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmjP6vJbYTED",
        "outputId": "c3331725-454d-4864-c57a-fe888d698924"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Match(a=0, b=0, size=5), Match(a=8, b=5, size=0)]\n",
            "similarity Score:  0.7692307692307693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#implementing to our problem\n",
        "#variables\n",
        "for i in list_of_uncorrect_words:\n",
        "  list_ratios=[]\n",
        "  for j in list_of_words:\n",
        "    string_incorr=i\n",
        "    string=j\n",
        "    temp = difflib.SequenceMatcher(None,string_incorr,string)\n",
        "    print(temp.get_matching_blocks())\n",
        "    print('similarity Score: ',temp.ratio())\n",
        "    list_ratios.append(temp.ratio())\n",
        "    #searching for the word of highest ratio\n",
        "  max_value = max(list_ratios)\n",
        "  index = list_ratios.index(max_value)\n",
        "  print(index)\n",
        "  print(list_of_words[index])\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPDE04hnaBQJ",
        "outputId": "21e93cf6-395c-4455-a1cf-666320d7c98c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Match(a=1, b=0, size=1), Match(a=3, b=1, size=1), Match(a=5, b=3, size=0)]\n",
            "similarity Score:  0.5\n",
            "[Match(a=0, b=0, size=1), Match(a=1, b=2, size=1), Match(a=5, b=3, size=0)]\n",
            "similarity Score:  0.5\n",
            "[Match(a=0, b=0, size=1), Match(a=5, b=5, size=0)]\n",
            "similarity Score:  0.2\n",
            "[Match(a=1, b=1, size=1), Match(a=5, b=4, size=0)]\n",
            "similarity Score:  0.2222222222222222\n",
            "[Match(a=5, b=4, size=0)]\n",
            "similarity Score:  0.0\n",
            "[Match(a=5, b=3, size=0)]\n",
            "similarity Score:  0.0\n",
            "[Match(a=3, b=4, size=1), Match(a=5, b=5, size=0)]\n",
            "similarity Score:  0.2\n",
            "[Match(a=0, b=4, size=1), Match(a=5, b=5, size=0)]\n",
            "similarity Score:  0.2\n",
            "[Match(a=3, b=0, size=1), Match(a=5, b=4, size=0)]\n",
            "similarity Score:  0.2222222222222222\n",
            "[Match(a=0, b=0, size=1), Match(a=3, b=2, size=1), Match(a=5, b=3, size=0)]\n",
            "similarity Score:  0.5\n",
            "[Match(a=3, b=5, size=1), Match(a=5, b=6, size=0)]\n",
            "similarity Score:  0.18181818181818182\n",
            "[Match(a=0, b=0, size=1), Match(a=5, b=6, size=0)]\n",
            "similarity Score:  0.18181818181818182\n",
            "[Match(a=0, b=0, size=1), Match(a=3, b=7, size=1), Match(a=5, b=8, size=0)]\n",
            "similarity Score:  0.3076923076923077\n",
            "[Match(a=0, b=4, size=1), Match(a=3, b=7, size=1), Match(a=5, b=8, size=0)]\n",
            "similarity Score:  0.3076923076923077\n",
            "[Match(a=0, b=3, size=1), Match(a=3, b=6, size=1), Match(a=5, b=7, size=0)]\n",
            "similarity Score:  0.3333333333333333\n",
            "[Match(a=0, b=3, size=1), Match(a=3, b=6, size=1), Match(a=5, b=7, size=0)]\n",
            "similarity Score:  0.3333333333333333\n",
            "[Match(a=0, b=5, size=1), Match(a=3, b=8, size=1), Match(a=5, b=9, size=0)]\n",
            "similarity Score:  0.2857142857142857\n",
            "[Match(a=0, b=4, size=1), Match(a=3, b=7, size=1), Match(a=5, b=8, size=0)]\n",
            "similarity Score:  0.3076923076923077\n",
            "[Match(a=0, b=4, size=1), Match(a=3, b=7, size=1), Match(a=5, b=8, size=0)]\n",
            "similarity Score:  0.3076923076923077\n",
            "[Match(a=0, b=0, size=1), Match(a=3, b=3, size=1), Match(a=5, b=6, size=0)]\n",
            "similarity Score:  0.36363636363636365\n",
            "[Match(a=0, b=0, size=1), Match(a=5, b=6, size=0)]\n",
            "similarity Score:  0.18181818181818182\n",
            "[Match(a=0, b=3, size=1), Match(a=5, b=5, size=0)]\n",
            "similarity Score:  0.2\n",
            "[Match(a=0, b=3, size=1), Match(a=5, b=5, size=0)]\n",
            "similarity Score:  0.2\n",
            "[Match(a=0, b=3, size=1), Match(a=5, b=5, size=0)]\n",
            "similarity Score:  0.2\n",
            "[Match(a=0, b=5, size=1), Match(a=5, b=7, size=0)]\n",
            "similarity Score:  0.16666666666666666\n",
            "[Match(a=0, b=4, size=1), Match(a=5, b=6, size=0)]\n",
            "similarity Score:  0.18181818181818182\n",
            "[Match(a=0, b=4, size=1), Match(a=5, b=6, size=0)]\n",
            "similarity Score:  0.18181818181818182\n",
            "[Match(a=3, b=2, size=2), Match(a=5, b=7, size=0)]\n",
            "similarity Score:  0.3333333333333333\n",
            "[Match(a=0, b=0, size=1), Match(a=1, b=2, size=1), Match(a=2, b=5, size=3), Match(a=5, b=8, size=0)]\n",
            "similarity Score:  0.7692307692307693\n",
            "[Match(a=1, b=5, size=1), Match(a=3, b=6, size=1), Match(a=5, b=7, size=0)]\n",
            "similarity Score:  0.3333333333333333\n",
            "[Match(a=2, b=1, size=1), Match(a=5, b=4, size=0)]\n",
            "similarity Score:  0.2222222222222222\n",
            "[Match(a=2, b=1, size=1), Match(a=5, b=5, size=0)]\n",
            "similarity Score:  0.2\n",
            "28\n",
            "thousand\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QYpQCynVLBCV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}